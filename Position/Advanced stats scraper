import os
import shutil
import requests
from bs4 import BeautifulSoup
import pandas as pd


years = list(range(2022,2023))

url_start = "https://www.basketball-reference.com/leagues/NBA_{}_play-by-play.html"

for year in years:
    url = url_start.format(year)
    data = requests.get(url)
    
    with open("{}.html".format(year), "w+", encoding="utf-8") as f:
        f.write(data.text)


dfs = []
for year in years:
    with open("{}.html".format(year), encoding="utf-8") as f:
        page = f.read()
        
    soup = BeautifulSoup(page, 'html.parser')
    soup.find('tr', class_="over_header").decompose()
    position_table = soup.find_all(id="all_pbp_stats")[0]
    positions = pd.read_html(str(position_table))[0]
    dfs.append(positions)
    
    
    positions = pd.concat(dfs)
    
    positions.to_csv("positions.csv", encoding="utf-8")
    
    positions[positions['Rk'] != 'Rk'][['Rk','Player', 'Pos', 'PG%','SG%', 'SF%','PF%','C%']].to_csv("filteredPositions.csv")
