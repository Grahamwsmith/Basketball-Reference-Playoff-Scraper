import os
import shutil
import requests
from bs4 import BeautifulSoup
import pandas as pd


years = list(range(2012,2023))
    
url_start = "https://www.basketball-reference.com/playoffs/NBA_{}.html"

for year in years:
    url = url_start.format(year)
    data = requests.get(url)
 
    with open("playoffs/{}.html".format(year), "w+", encoding="utf-8") as f:
        f.write(data.text)
        
        
 dfs = []
for year in years:
    with open("playoffs/{}.html".format(year), encoding="utf-8") as f:
        page = f.read()
        
    soup = BeautifulSoup(page, 'html.parser')
    soup.find('tr', class_="over_header").decompose()
    advanced_table = soup.find_all(id="advanced-team")[0]
    playoffs = pd.read_html(str(advanced_table))[0]
    playoffs["Year"] = year
    dfs.append(playoffs)


playoffs = pd.concat(dfs)

playoffs.to_csv("playoff.csv")mm
